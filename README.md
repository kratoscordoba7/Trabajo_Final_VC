<h1 align="center">ü§ñTrabajo Final - VC Reconocimiento facial 24/25</h1>

<div align="center">
<img width="500px" src="https://github.com/user-attachments/assets/289b1a6a-7d16-42c2-8441-e4f4a2aa0509">
</div>

Se ha completado el **Trabajo final** para la asignatura **Visi√≥n por Computador**.  Reconocimiento Facial. Consiste en aplicar distintas tecnicas
de recocimiento facial para poder reconocer personas.

*Trabajo realizado por*:

[![GitHub](https://img.shields.io/badge/GitHub-Heliot%20J.%20Segura%20Gonzalez-darkblue?style=flat-square&logo=github)](https://github.com/kratoscordoba7)

[![GitHub](https://img.shields.io/badge/GitHub-Alejandro%20D.%20Arzola%20Saavedra%20-purple?style=flat-square&logo=github)](https://github.com/AlejandroDavidArzolaSaavedra)

## üõ†Ô∏è Tecnolog√≠as Utilizadas

[![Python](https://img.shields.io/badge/Python-%233776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![MySQL](https://img.shields.io/badge/MySQL-%234479A1?style=for-the-badge&logo=mysql&logoColor=white)](https://www.mysql.com/)

## üõ†Ô∏è Librer√≠as Utilizadas

[![OpenCV](https://img.shields.io/badge/OpenCV-%230076A8?style=for-the-badge&logo=opencv&logoColor=white)](https://opencv.org/)
[![Imutils](https://img.shields.io/badge/Imutils-%A020F0?style=for-the-badge)](https://pypi.org/project/imutils/)
[![OS](https://img.shields.io/badge/OS-%232196F3?style=for-the-badge&logo=linux&logoColor=white)](https://en.wikipedia.org/wiki/Operating_system)
[![NumPy](https://img.shields.io/badge/NumPy-%23013243?style=for-the-badge&logo=numpy&logoColor=white)](https://numpy.org/)
[![Deque](https://img.shields.io/badge/Deque-%23E34F26?style=for-the-badge&logo=python&logoColor=white)](https://docs.python.org/3/library/collections.html#collections.deque)
[![SciPy](https://img.shields.io/badge/SciPy-%23045A8D?style=for-the-badge&logo=scipy&logoColor=white)](https://scipy.org/)
[![Logging](https://img.shields.io/badge/Logging-%23FF0000?style=for-the-badge&logo=python&logoColor=white)](https://docs.python.org/3/library/logging.html)
[![pyttsx3](https://img.shields.io/badge/pyttsx3-%23013243?style=for-the-badge&logo=python&logoColor=white)](https://pyttsx3.readthedocs.io/en/latest/)

---

## üöÄ C√≥mo empezar

Para comenzar con el proyecto, sigue estos pasos:

> [!NOTE]  
> Debes de situarte en un environment configurado como se defini√≥ en el cuaderno de la pr√°ctica de [otsedom](https://github.com/otsedom/otsedom.github.io/blob/main/VC/P1/README.md#111-comandos-basicos-de-anaconda).

### Paso 1: Abrir VSCode y situarse en el directorio:
   
   `C:\Users\TuNombreDeUsuario\anaconda3\envs\Trabajo_Final_VC
   
### Paso 2: Clonar y trabajar en el proyecto localmente (VS Code)
1. **Clona el repositorio**: Ejecuta el siguiente comando en tu terminal para clonar el repositorio:
   ```bash
   git clone https://github.com/kratoscordoba7/Trabajo_Final_VC.git
   ```
2. Una vez clonado, todos los archivos han de estar situado en el environment del paso 1

### Paso 3: Abrir Anaconda prompt y activar el environment:
   ```bash
   conda activate NombreDeTuEnvironment
   ```

### Paso 4: Instalaci√≥n
Para instalar estas librer√≠as, ejecuta los siguientes comandos:

```bash
pip install opencv-contrib-python numpy scipy imutils pyttsx3
```
o

```bash
pip install -r requirements.txt
```
Tras estos pasos deber√≠a poder ejecutar el proyecto localmente

<h2>üìã Motivaci√≥n/argumentaci√≥n del trabajo</h2>

<img align="left" width="200px" src="https://github.com/user-attachments/assets/7573a72a-704f-4b29-a32a-7dd498ed0183">  
Nuestro trabajo de curso se centra en el <b>reconocimiento facial</b>, una tem√°tica que nos despierta <b>curiosidad</b> üßê debido al funcionamiento y comportamiento de las <b>aplicaciones t√≠picas nativas en dispositivos m√≥viles</b> üì± de la √∫ltima d√©cada. 
<br><br>
Consideramos que el <b>reconocimiento facial</b> es un √°rea <b>fascinante</b> ‚ú® que permite aplicar <b>t√©cnicas y metodolog√≠as avanzadas de visi√≥n por computador</b> , ofreciendo una <b>oportunidad √∫nica</b> para explorar y desarrollar <b>soluciones innovadoras</b>. üí°
<br><br>

### Alcance y objetivo de la propuesta

Nuestro objetivo ha sido poder **reconocer personas** y **identificarlas**, ya sea de manera individual o en grupos, explorando distintas t√©cnicas, librer√≠as y tecnolog√≠as que nos permitieran investigar y probar hasta **d√≥nde pod√≠amos llegar**. üîçüí° Durante el proceso, nos enfocamos en experimentar con diversas herramientas y enfoques, con la intenci√≥n de maximizar el rendimiento y obtener resultados √≥ptimos. üë©‚Äçüíªüìä

### Uso/Controles üìñüíª

Una vez tengamos todas las librer√≠as instaladas, debemos dirigirnos al archivo `main.py` y ejecutarlo. Para ello, basta con hacer clic en el bot√≥n indicado en la imagen siguiente: 

<div align="center">
   <img width="800px" src="https://github.com/user-attachments/assets/9fbc2553-0708-4b54-b8f7-93a1f19b5e54">
</div>

Al iniciar el programa, este nos dar√° la bienvenida y nos ofrecer√° dos opciones para seleccionar. Estas opciones est√°n dise√±adas pensando en la flexibilidad del usuario:  

1Ô∏è‚É£ **Modo 1:** Capturar, entrenar y reconocer el rostro.  
2Ô∏è‚É£ **Modo 2:** Reconocer el rostro directamente, sin necesidad de un entrenamiento previo.  

Esta separaci√≥n permite que el usuario pueda elegir lo que necesita sin tener que seguir pasos secuenciales innecesarios. Si solo deseas reconocer tu rostro sin haberlo entrenado antes, ¬°no hay problema! Puedes seleccionar directamente el Modo 2.  

---

#### **Modo 1: Captura y Entrenamiento üé•‚ú®**

Si el usuario introduce "1", el programa solicitar√° un nombre que se utilizar√° para etiquetar correctamente el rostro durante el reconocimiento. Por ejemplo:  

<img src="/assets/img/modo1.gif">

Tras escribir el nombre, se abrir√° una ventana con la c√°mara. En esta ventana, se indicar√° que al pulsar la tecla **"S"**, comenzar√° la captura del rostro. Para obtener mejores resultados en el reconocimiento, se recomienda:  

- Mirar directamente a la c√°mara.  
- Girar la cabeza suavemente hacia los lados.  

Aqu√≠ puedes ver un ejemplo del proceso:  

<div align="center">
   <img src="/assets/img/modo1_parte2.gif">
</div>

#### **Modo 2: Reconocimiento Directo üîçü§ñ**

Si el usuario introduce "2", el programa intentar√° reconocer el rostro directamente.  

- Si logra identificar el rostro, aparecer√° etiquetado con el nombre previamente entrenado.  
- Si no logra identificarlo, el sistema mostrar√° la etiqueta **"Desconocido"**.  

Aqu√≠ tienes una demostraci√≥n del funcionamiento:  

<div align="center">
   <img src="/assets/img/modo2.gif">
</div>

###  Descripci√≥n t√©cnica del trabajo realizado

Se enfatizan los aspectos m√°s relevantes del proyecto.

La clase FaceIdentity est√° dise√±ada para representar una identidad √∫nica de un rostro detectado en un sistema de seguimiento. Rastrear y gestionar la informaci√≥n de un rostro detectado, asoci√°ndolo con un identificador √∫nico y usando un tracker para realizar seguimiento entre frames.

```Python
class FaceIdentity:
    def __init__(self, face_id, initial_centroid, frames_to_confirm, initial_box, frame):
        """
        Inicializa una nueva identidad de rostro.

        :param face_id: Identificador √∫nico de la identidad.
        :param initial_centroid: Tupla (x, y) del centroide inicial del rostro.
        :param frames_to_confirm: N√∫mero de frames para confirmar la etiqueta.
        :param initial_box: Tupla (x, y, x1, y1) de la caja inicial del rostro.
        :param frame: Frame actual para inicializar el tracker.
        """
        self.id = face_id
        self.centroid = initial_centroid
        self.labels = deque(maxlen=frames_to_confirm)
        self.confirmed_label = None
        self.missing_frames = 0  # Contador de frames donde no se ha detectado el rostro
        self.tracker = cv2.TrackerCSRT_create()
        x, y, x1, y1 = initial_box
        w, h = x1 - x, y1 - y
        self.tracker.init(frame, (x, y, w, h))
        logging.info(f"Creada nueva identidad: ID {self.id} en centroid {self.centroid}")

```

El siguiente fragmento utiliza el algoritmo H√∫ngaro para resolver la asociaci√≥n entre las detecciones de rostros actuales y las identidades previamente rastreadas. Es crucial porque:

```Python
# Resolver la asignaci√≥n √≥ptima
row_ind, col_ind = linear_sum_assignment(cost_matrix)

# Asignar detecciones a identidades
for row, col in zip(row_ind, col_ind):
    distance = cost_matrix[row][col]
    if distance < max_distance:
        identities[row].centroid = detected_centroids[col]
        identities[row].missing_frames = 0
        assigned_identities.add(row)
        assigned_detections.add(col)
```

1. **Manejo de m√∫ltiples rostros**:
   - Al usar una matriz de costos (distancias entre centroides de las detecciones actuales y las identidades rastreadas), permite asociar de manera √≥ptima los rostros detectados con sus correspondientes identidades en el menor costo posible.

2. **Rendimiento y precisi√≥n**:
   - Evita errores como asignaciones incorrectas o duplicadas mediante el c√°lculo preciso de distancias y la comparaci√≥n con un umbral (`max_distance`).

3. **Escalabilidad**:
   - El enfoque permite que el sistema maneje m√∫ltiples rostros en tiempo real, algo fundamental en aplicaciones de reconocimiento facial.

4. **Prevenci√≥n de errores**:
   - Si una detecci√≥n no cumple con el criterio de distancia, no se asigna, reduciendo la probabilidad de errores en la identificaci√≥n.

---

### üìÇ **Estructura del Proyecto**  

```
   üìú `main.py` Programa principal que coordina la ejecuci√≥n del proyecto.  
   üì∏ `capture_faces.py` Script encargado de la captura de rostros utilizando SSD (Single Shot Detector).  
   ü§ñ `train_recognizer.py` Script que realiza el entrenamiento del modelo** para el reconocimiento facial.  
   üïµÔ∏è `recognize_faces.py` Script encargado del reconocimiento facial a partir de los datos entrenados.  
   üìÇ `userdata/`  Carpeta que almacena todos los rostros capturados** durante el proceso.  
```

Los dem√°s archivos que encontrar√°s en el proyecto son autogenerados por el propio programa, o necesarios para el proceso de entrenamiento.

### Conclusiones y propuestas de ampliaci√≥n, propuestas adicionales

La verdad es que hemos aprendido mucho sobre las t√©cnicas implementadas y, a trav√©s de pruebas e investigaci√≥n, logramos alcanzar el objetivo que nos hab√≠amos propuesto inicialmente. Aunque algunas de estas t√©cnicas las contempl√°bamos dentro del √°mbito de la biometr√≠a de la asignatura, el hecho de probarlas y comprobar que realmente funcionan nos sorprendi√≥ gratamente.

- Una ampliaci√≥n interesante, observando diversas p√°ginas sobre reconocimiento facial, ser√≠a integrar el proyecto en una **Raspberry Pi**. La raz√≥n es que podr√≠a resultar muy √∫til aplicarlo en la entrada de una casa, donde la Raspberry Pi ser√≠a capaz de reconocer a la persona y abrir la puerta autom√°ticamente. Adem√°s, podr√≠a encender las luces y realizar otras acciones dentro de la casa una vez haya reconocido al usuario.

- Otra aplicaci√≥n potencial ser√≠a su integraci√≥n en plataformas web, como aquellas utilizadas por la **tesorer√≠a** o sitios que requieren certificados como el DNI electr√≥nico. Esto podr√≠a mejorar la seguridad, evitando la necesidad de introducir contrase√±as o recibir c√≥digos PIN, ya que el reconocimiento facial servir√≠a como una forma de autenticaci√≥n m√°s r√°pida y segura.

- Tambi√©n ser√≠a interesante integrar esta tecnolog√≠a en una **aplicaci√≥n m√≥vil** para el control de asistencia. Esta ser√≠a una medida adicional de seguridad, ya que permitir√≠a verificar que la persona que pasa la asistencia es realmente quien dice ser, evitando que alguien pase la asistencia de otra persona utilizando solo sus credenciales. Esto ocurre con frecuencia en algunas universidades, donde se verifica la asistencia de manera digital, pero a menudo una persona pasa la asistencia de otro solo por compartir el c√≥digo o las credenciales. Con esta aplicaci√≥n, se podr√≠a requerir que el usuario se reconozca mediante reconocimiento facial y se tome una foto al momento de registrar su asistencia.


### Indicaci√≥n de herramientas/tecnolog√≠as con las que les hubiera gustado contar / Aspectos a mejorar

Nos hubiera encantado contar con herramientas que pudieran integrar OpenCV con el desarrollo web de manera f√°cil, para mejorar la UI e incluso implementarlas en una aplicaci√≥n web. Otras herramientas, como dlib, que generan muchos conflictos, tambi√©n nos hubiera gustado probarlas. Vimos que tienen mucho potencial, pero no pudimos probarlas adecuadamente debido a problemas de incompatibilidades. Librer√≠as como face_recognition requer√≠an un alto consumo de recursos computacionales y funcionaban de manera bastante lenta. Dado que busc√°bamos una soluci√≥n r√°pida, decidimos no optar por esta opci√≥n, aunque hubiera sido interesante probarla.

### Reuniones del grupo

Hemos tenido varias reuniones durante las clases pr√°cticas, tanto con el profesor como con el propio equipo de desarrollo. Adem√°s, cada semana, o casi siempre, nos notificamos sobre el estado y avance del desarrollo de la aplicaci√≥n.

### Cr√©ditos materiales no originales del grupo

Algunas im√°genes utilizadas en el README y en el documento fueron generadas por DALL-E 3, y el video promocional fue desarrollado por Vidnoz.

### Entrenamiento

En cuanto al entrenamiento, utilizamos diferentes m√©todos como LBPH, Eigenfaces y Fisherfaces. Adem√°s, contamos con un proceso de entrenamiento que trabaja con un vector de descriptores, al cual le aplicamos un sumatorio y una ponderaci√≥n en funci√≥n de su desempe√±o. Estos descriptores son optimizados mediante algoritmos gen√©ticos para acercarlos lo m√°s posible a la soluci√≥n ideal.  Tiene un comportamiento similar al de una neurona, es decir, estamos construyendo una funci√≥n a partir de los descriptores, que permite que estos se comporten de manera que faciliten el reconocimiento facial.

La f√≥rmula matem√°tica es la siguiente:

$$
S(w_1, w_2, w_3, w_n..) = \sum_{i=1}^{n} \left( w_1 \cdot F_i(w) + w_2 \cdot E_i(w) + w_3 \cdot L_i(w) \cdot\cdot\cdot\right)
$$

Donde:

$$ 
S(w_1, w_2, w_3) 
$$ 

es el puntaje total ponderado.

$$ 
F_i(w) \), \( E_i(w) \), y \( L_i(w) 
$$ 

son los resultados de cada t√©cnica (Fisherfaces, Eigenfaces y LBP) para el **i-√©simo** caso de prueba (por ejemplo, una imagen o un conjunto de caracter√≠sticas).

$$ 
w_1, w_2, w_3 
$$ 

son los **pesos** asignados por el algoritmo gen√©tico para cada t√©cnica.

$$ 
n 
$$ 

es el n√∫mero total de casos de prueba (pueden ser varias im√°genes o muestras).

---

Algoritmo del M√©todo Eigenfaces

1. **C√°lculo de la media:**
   
$$
\mu = \frac{1}{n} \sum_{i=1}^n x_i
$$

2. **C√°lculo de la matriz de covarianza \( S \):**
   
$$
S = \frac{1}{n} \sum_{i=1}^n (x_i - \mu)(x_i - \mu)^T
$$

3. **C√°lculo de los autovalores \( \lambda_i \) y autovectores \( v_i \) de \( S \):**

$$
S v_i = \lambda_i v_i, \quad i = 1, 2, \dots, n
$$

4. **Ordenar los autovectores:**
  
5. **Proyecci√≥n al subespacio PCA:**
   Las \( k \) componentes principales del vector observado \( z \) est√°n dadas por:

$$
y = W^T (z - \mu)
$$
   
donde 

$$
\( W = [v_1, v_2, \dots, v_k] \).
$$


---


El **LBP**  \((x_c, y_c)\) se calcula como:

$$
   LBP(x_c, y_c) = \sum_{p=0}^{P-1} 2^p \cdot s(i_p - i_c)
$$

Para cada pixel vecino, se compara su intensidad con la intensidad del pixel central 

$$
s(x) = 
\begin{cases} 
1 & \text{si } x \geq 0 \\
0 & \text{si } x < 0
\end{cases}
$$

---

La **funci√≥n objetivo** de Eigenface:

Primero se calcula la **media de las im√°genes** en el conjunto de entrenamiento y luego se calcula la **matriz de covarianza** entre todas las im√°genes.

$$
   \mu = \frac{1}{N} \sum_{i=1}^{N} x_i
$$

$$
   C = \frac{1}{N} \sum_{i=1}^{N} (x_i - \mu)(x_i - \mu)^T
$$

Los **eigenvectores vi** y **eigenvalores** de la matriz de covarianza proporcionan la base del espacio de menor dimensi√≥n que describe mejor la variabilidad de los datos:

$$
C v_i = \lambda_i \cdot v_i \quad \text{para} \quad i = 1, 2, \ldots, n
$$

Las im√°genes de entrada se proyectan sobre el espacio de los eigenfaces (componentes principales) para obtener una representaci√≥n de baja dimensi√≥n

$$
E(w) = \text{Proyecci√≥n de la imagen en el subespacio de Eigenfaces}
$$






### V√≠deo resumen de venta del trabajo

Aqui debe ir el video

<video width="320" height="240" controls>
  <source src="movie.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>


---


> [!IMPORTANT]  
> Los decisiones de las implementaciones realizadas han sido recomendadas por [otsedom](https://github.com/otsedom/otsedom.github.io/tree/main/VC).

---

## üìö Fuentes y Tecnolog√≠as Utilizadas

1. **Documentaci√≥n Oficial de OpenCV** [Enlace a la documentaci√≥n](https://docs.opencv.org/)
2. **Tutorial sobre Reconocimiento Facial con OpenCV**  [Enlace al tutorial](https://docs.opencv.org/4.x/da/d60/tutorial_face_main.html#tutorial_face_eigenfaces)
3. **Introducci√≥n al Algoritmo H√∫ngaro**  [Enlace al art√≠culo](https://en.wikipedia.org/wiki/Hungarian_algorithm)
4. **Implementaci√≥n de Algoritmos Gen√©ticos en Python** [Enlace al blog](https://anderfernandez.com/blog/algoritmo-genetico-en-python/)
5. **Reconocimiento Facial con Python y OpenCV**  [Enlace al tutorial](https://omes-va.com/face-recognition-python/)
6. **Gu√≠a del Algoritmo H√∫ngaro en Python**  [Enlace al art√≠culo](https://python.plainenglish.io/hungarian-algorithm-introduction-python-implementation-93e7c0890e15)
7. **Universidad Michigan** [Enlace al pdf](https://web.eecs.umich.edu/~jjcorso/t/598F14/files/lecture_eigenfaces.pdf)
8. **Rasberry Pi Reconocimiento Facial** [Enlace al art√≠culo](https://pyimagesearch.com/2018/06/25/raspberry-pi-face-recognition/)

---

<img align="left" width="160" height="160" src="https://github.com/user-attachments/assets/ed3617f0-9c77-44b2-a15b-b48052b0c9a4"></a>

**Universidad de Las Palmas de Gran Canaria**  

EII - Grado de Ingenier√≠a Inform√°tica  
Obra bajo licencia de Creative Commons Reconocimiento - No Comercial 4.0 Internacional

Tienen total libertad para utilizar el c√≥digo. Espero que este repositorio haya sido de utilidad. Al final, queriamos ver qu√© logr√°bamos alcanzar con los recursos disponibles.

---
